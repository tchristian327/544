{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# XML, HTML, and Web Scraping\n",
        "\n",
        "JSON and XML are two different ways to represent hierarchical data. Which one is better? There are lots of articles online which discuss similarities and differences between JSON and XML and their advantages and disadvantages. Both formats are still in current usage, so it is good to be familiar with both. However, JSON is more common, so we'll focus on working with JSON representations of hierarchical data.\n",
        "\n",
        "The reading covered an example of using Beautiful Soup to parse XML. Rather than doing another example XML now, we'll skip straight to scraping HTML from a webpage. Both HTML and XML can be parsed in a similar way with Beautiful Soup."
      ],
      "metadata": {
        "id": "qrJX4FDa8oA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "XZhT8jhbuZSg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping an HTML table with Beautiful Soup"
      ],
      "metadata": {
        "id": "ApqnMQ4iV4qu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open the URL https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population and scroll down until you see a table of the cities in the U.S. with population over 100,000 (as of Jul 1, 2022). We'll use Beautiful Soup to scrape information from this table."
      ],
      "metadata": {
        "id": "9SD7XOs_So3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in the HTML from the ULR using the `requests` library."
      ],
      "metadata": {
        "id": "HRmnzgaQS_T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(\"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\")"
      ],
      "metadata": {
        "id": "xvYzbSospYVu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Beautiful Soup to parse this string into a tree called `soup`"
      ],
      "metadata": {
        "id": "YJ1Swg6B82_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(response.content, \"html.parser\")"
      ],
      "metadata": {
        "id": "e0jpmfwtpaEB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find an HTML tag corresponding to a specific element on a webpage, right-click on it and choose \"Inspect element\". Go to the cities table Wikipedia page and do this now.\n",
        "\n",
        "You should find that the cities table on the Wikipedia page corresponds to the element\n",
        "\n",
        "```\n",
        "<table class=\"wikitable sortable jquery-tablesorter\" style=\"text-align:center\">\n",
        "```"
      ],
      "metadata": {
        "id": "lFxGW_KIDjnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many `<table>` tags on the page."
      ],
      "metadata": {
        "id": "DR50aTBZEwov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(soup.find_all(\"table\"))"
      ],
      "metadata": {
        "id": "4691d-EGEwc0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use attributes like `class=` and `style=` to narrow down the list."
      ],
      "metadata": {
        "id": "H1xslM2yE1GI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(soup.find_all(\"table\",\n",
        "                  attrs={\n",
        "                      \"class\": \"wikitable sortable\",\n",
        "                      \"style\": \"text-align:center\"}\n",
        "                  ))"
      ],
      "metadata": {
        "id": "E0Q0sa46DvTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b57764-ab4e-462f-d060-dbc2d341a8b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, you can manually inspect the tables on the webpage to find that the one we want is the first one (see `[0]` below). We'll store this as `table`."
      ],
      "metadata": {
        "id": "ndnRSJJiFFby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table = soup.find_all(\"table\",\n",
        "                  attrs={\n",
        "                      \"class\": \"wikitable sortable\",\n",
        "                      \"style\": \"text-align:center\"}\n",
        "                  )[0]"
      ],
      "metadata": {
        "id": "sRBSqVGlYhuT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "d1fbb0c1-ce11-489b-cbe6-026787cec704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-30c9df03cb78>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m table = soup.find_all(\"table\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                   attrs={\n\u001b[1;32m      3\u001b[0m                       \u001b[0;34m\"class\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"wikitable sortable\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \"style\": \"text-align:center\"}\n\u001b[1;32m      5\u001b[0m                   )[0]\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now you will write code to scrape the information in `table` to create a Pandas data frame with one row for each city and columns for: city, state, population (2022 estimate), and 2020 land area (sq mi).** Refer to the Notes/suggestions below as you write your code. A few Hints are provided further down, but try coding first before looking at the hints."
      ],
      "metadata": {
        "id": "j4AWo3QoYqNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes/suggestions:\n",
        "\n",
        "- Use as a guide the code from the reading that produced the data frame of Statistics faculty\n",
        "- Inspect the page source as you write your code\n",
        "- You will need to write a loop to get the information for all cities, but you might want to try just scraping the info for New York first\n",
        "- You will need to pull the text from the tag. If `.text` returns text with \"\\n\" at the end, try `.get_text(strip = True)` instead of `.text`\n",
        "- Don't forget to convert to a Pandas Data Frame; it should have 333 rows and 4 columns\n",
        "- The goal of this exercise is just to create the Data Frame. If you were going to use it --- e.g., what is the population density for all cities in CA? --- then you would need to clean the data first (to clean strings and convert to quantitative). (You can use Beautiful Soup to do some of the cleaning for you, but that goes beyond our scope.)"
      ],
      "metadata": {
        "id": "KfRx2_XlDUqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE. ADD AS MANY CELLS AS NEEDED"
      ],
      "metadata": {
        "id": "msKiUcOZpSX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1M23w-PPtUyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hints:\n",
        "\n",
        "- Each city is a row in the table; find all the `<tr>` tags to find all the cities\n",
        "- Look for the `<td>` tag to see table entries within a row\n",
        "- The rank column is represented by `<th>` tags, rather than `<td>` tags. So within a row, the first (that is, `[0]`) `<td>` tag corresponds to the city name."
      ],
      "metadata": {
        "id": "6s3tH82XZ1X0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aside: Scraping an HTML table with Pandas\n",
        "\n"
      ],
      "metadata": {
        "id": "pIW4UgURNdhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Pandas command `read_html` can be used to scrape information from an HTML table on a webpage.\n",
        "\n",
        "We can call `read_html` on the URL."
      ],
      "metadata": {
        "id": "R2ufAAMGYenH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_html(\"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\")"
      ],
      "metadata": {
        "id": "YnGD1hMbpv7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c3f060-3d3f-46ce-b591-28fd19a0cf34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[                    Population tables of U.S. cities\n",
              " 0  The skyline of New York City, the most populou...\n",
              " 1                                             Cities\n",
              " 2  Population AreaDensityEthnic identityForeign-b...\n",
              " 3                                        Urban areas\n",
              " 4             Populous cities and metropolitan areas\n",
              " 5                                 Metropolitan areas\n",
              " 6  184 combined statistical areas935 core-based s...\n",
              " 7                                        Megaregions\n",
              " 8  See related population listsNorth American met...\n",
              " 9                                                vte,\n",
              "     0                               1\n",
              " 0 NaN                   State capital\n",
              " 1 NaN              State largest city\n",
              " 2 NaN  State capital and largest city\n",
              " 3 NaN                 Federal capital,\n",
              "             City  ST 2023 estimate 2020 census  Change 2020 land area          \\\n",
              "             City  ST 2023 estimate 2020 census  Change            mi2     km2   \n",
              " 0    New York[c]  NY       8258035     8804190  −6.20%          300.5   778.3   \n",
              " 1    Los Angeles  CA       3820914     3898747  −2.00%          469.5  1216.0   \n",
              " 2        Chicago  IL       2664452     2746388  −2.98%          227.7   589.7   \n",
              " 3        Houston  TX       2314157     2304580  +0.42%          640.4  1658.6   \n",
              " 4        Phoenix  AZ       1650070     1608139  +2.61%          518.0  1341.6   \n",
              " ..           ...  ..           ...         ...     ...            ...     ...   \n",
              " 331         Yuma  AZ        100858       95548  +5.56%          120.7   312.6   \n",
              " 332  New Bedford  MA        100695      101079  −0.38%           20.0    51.8   \n",
              " 333   Suffolk[l]  VA        100659       94324  +6.72%          399.2  1033.9   \n",
              " 334     Hesperia  CA        100633       99818  +0.82%           72.7   188.3   \n",
              " 335    Davenport  IA        100354      101724  −1.35%           63.8   165.2   \n",
              " \n",
              "     2020 density                                      Location  \n",
              "            / mi2  / km2                               Location  \n",
              " 0          29298  11312    40°40′N 73°56′W﻿ / ﻿40.66°N 73.94°W  \n",
              " 1           8304   3206  34°01′N 118°25′W﻿ / ﻿34.02°N 118.41°W  \n",
              " 2          12061   4657    41°50′N 87°41′W﻿ / ﻿41.84°N 87.68°W  \n",
              " 3           3599   1390    29°47′N 95°23′W﻿ / ﻿29.79°N 95.39°W  \n",
              " 4           3105   1199  33°34′N 112°05′W﻿ / ﻿33.57°N 112.09°W  \n",
              " ..           ...    ...                                    ...  \n",
              " 331          792    306  32°31′N 114°31′W﻿ / ﻿32.52°N 114.52°W  \n",
              " 332         5054   1951    41°40′N 70°56′W﻿ / ﻿41.66°N 70.94°W  \n",
              " 333          236     91    36°42′N 76°38′W﻿ / ﻿36.70°N 76.63°W  \n",
              " 334         1373    530  34°24′N 117°19′W﻿ / ﻿34.40°N 117.32°W  \n",
              " 335         1594    615    41°34′N 90°36′W﻿ / ﻿41.56°N 90.60°W  \n",
              " \n",
              " [336 rows x 10 columns],\n",
              "         Population  Number of municipal governments\n",
              " 0       1,000,000+                                9\n",
              " 1  700,000–999,999                               11\n",
              " 2  500,000–699,999                               18\n",
              " 3  400,000–499,999                               11\n",
              " 4  300,000–399,999                               20\n",
              " 5  200,000–299,999                               55\n",
              " 6  100,000–199,999                              212\n",
              " 7            Total                              336,\n",
              "                                                 State  Number of listed cities\n",
              " 0                                          California                       74\n",
              " 1                                               Texas                       42\n",
              " 2                                             Florida                       23\n",
              " 3                                             Arizona                       13\n",
              " 4                                            Colorado                       12\n",
              " 5                                      North Carolina                       10\n",
              " 6                           Massachusetts, Washington                        9\n",
              " 7                         Georgia, Illinois, Virginia                        8\n",
              " 8                                Michigan, New Jersey                        7\n",
              " 9   Missouri, Indiana, New York, Ohio, Oregon, Ten...                        6\n",
              " 10         Alabama, Connecticut, Kansas, Nevada, Utah                        5\n",
              " 11                                Louisiana, Oklahoma                        4\n",
              " 12  Iowa, Idaho, Minnesota, New Mexico, Pennsylvan...                        3\n",
              " 13                       Arkansas, Kentucky, Nebraska                        2\n",
              " 14  Alaska, District of Columbia, Hawaii, Maryland...                        1\n",
              " 15   Delaware, Maine, Vermont, West Virginia, Wyoming                        0,\n",
              "   Municipio  2023 estimate  2020 census  Change 2020 land area  \\\n",
              " 0  San Juan         333005       342259  −2.70%     39.8 sq mi   \n",
              " 1   Bayamón         180835       185187  −2.35%     27.0 sq mi   \n",
              " 2  Carolina         150843       154815  −2.57%     20.7 sq mi   \n",
              " 3     Ponce         130251       137491  −5.27%     28.4 sq mi   \n",
              " 4    Caguas         124608       127244  −2.07%     10.9 sq mi   \n",
              " \n",
              "   2020 land area.1  2020 density 2020 density.1  \\\n",
              " 0        103.1 km2   8,599/sq mi      3,320/km2   \n",
              " 1         69.9 km2   6,859/sq mi      2,648/km2   \n",
              " 2         53.6 km2   7,479/sq mi      2,888/km2   \n",
              " 3         73.6 km2   4,841/sq mi      1,869/km2   \n",
              " 4         28.2 km2  11,674/sq mi      4,507/km2   \n",
              " \n",
              "                               Location  \n",
              " 0  18°24′N 66°04′W﻿ / ﻿18.40°N 66.06°W  \n",
              " 1  18°23′N 66°10′W﻿ / ﻿18.38°N 66.16°W  \n",
              " 2  18°25′N 65°59′W﻿ / ﻿18.41°N 65.98°W  \n",
              " 3  18°00′N 66°37′W﻿ / ﻿18.00°N 66.62°W  \n",
              " 4  18°14′N 66°02′W﻿ / ﻿18.23°N 66.04°W  ,\n",
              "    Census- designated place  ST 2020 census 2010 census    Change  \\\n",
              "    Census- designated place  ST 2020 census 2010 census    Change   \n",
              " 0                 Arlington  VA      238643      207627   +14.94%   \n",
              " 1                Enterprise  NV      221831      108481  +104.49%   \n",
              " 2             Spring Valley  NV      215597      178395   +20.85%   \n",
              " 3             Sunrise Manor  NV      205618      189372    +8.58%   \n",
              " 4                  Paradise  NV      191238      223167   −14.31%   \n",
              " 5                  Metairie  LA      143507      138481    +3.63%   \n",
              " 6          East Los Angeles  CA      118786      126496    −6.10%   \n",
              " 7                   Brandon  FL      114626      103483   +10.77%   \n",
              " 8             The Woodlands  TX      114436       93847   +21.94%   \n",
              " 9              Lehigh Acres  FL      114287       86784   +31.69%   \n",
              " 10              Spring Hill  FL      113568       98621   +15.16%   \n",
              " 11                Riverview  FL      107396       71050   +51.16%   \n",
              " 12                 Columbia  MD      104681       99615    +5.09%   \n",
              " 13          Highlands Ranch  CO      103444       96713    +6.96%   \n",
              " \n",
              "    2020 land area          2020 density        \\\n",
              "               mi2      km2        / mi2 / km2   \n",
              " 0            26.0   67.340         9179  3544   \n",
              " 1            66.0  170.939         3361  1298   \n",
              " 2            35.5   91.945         6073  2345   \n",
              " 3            33.7   87.283         6101  2356   \n",
              " 4            42.4  109.815         4510  1740   \n",
              " 5            23.3   60.347         6159  2378   \n",
              " 6             7.5   19.425        15838  6115   \n",
              " 7            33.1   85.729         3463  1337   \n",
              " 8            43.3  112.146         2643  1020   \n",
              " 9            92.7  240.092         1233   476   \n",
              " 10           59.9  155.140         1896   732   \n",
              " 11           46.2  119.657         2325   898   \n",
              " 12           31.9   82.621         3282  1267   \n",
              " 13           24.3   62.937         4257  1644   \n",
              " \n",
              "                                  Location  \n",
              "                                  Location  \n",
              " 0     38°53′N 77°06′W﻿ / ﻿38.88°N 77.10°W  \n",
              " 1   36°01′N 115°14′W﻿ / ﻿36.01°N 115.23°W  \n",
              " 2   36°06′N 115°16′W﻿ / ﻿36.10°N 115.26°W  \n",
              " 3   36°11′N 115°03′W﻿ / ﻿36.18°N 115.05°W  \n",
              " 4   36°05′N 115°08′W﻿ / ﻿36.09°N 115.14°W  \n",
              " 5     30°00′N 90°11′W﻿ / ﻿30.00°N 90.18°W  \n",
              " 6   34°02′N 118°10′W﻿ / ﻿34.03°N 118.17°W  \n",
              " 7     27°56′N 82°18′W﻿ / ﻿27.94°N 82.30°W  \n",
              " 8     30°10′N 95°31′W﻿ / ﻿30.17°N 95.51°W  \n",
              " 9     26°37′N 81°38′W﻿ / ﻿26.61°N 81.64°W  \n",
              " 10    28°29′N 82°32′W﻿ / ﻿28.48°N 82.53°W  \n",
              " 11    27°49′N 82°18′W﻿ / ﻿27.82°N 82.30°W  \n",
              " 12    39°12′N 76°52′W﻿ / ﻿39.20°N 76.86°W  \n",
              " 13  39°32′N 104°58′W﻿ / ﻿39.54°N 104.97°W  ,\n",
              "               City  ST  2023 estimate  Peak population % decline from peak  \\\n",
              " 0        Allegheny  PA            NaN           129896                 NaN   \n",
              " 1         Brooklyn  NY            NaN           806343                 NaN   \n",
              " 2           Camden  NJ        71100.0           124555             −42.92%   \n",
              " 3           Canton  OH        69197.0           116912             −40.81%   \n",
              " 4   Citrus Heights  CA        86239.0           107439             −19.73%   \n",
              " 5        Daly City  CA        99833.0           104901              −4.83%   \n",
              " 6           Duluth  MN        87680.0           107312             −18.29%   \n",
              " 7             Erie  PA        92957.0           138440             −32.85%   \n",
              " 8       Fall River  MA        93840.0           120485             −22.11%   \n",
              " 9      Federal Way  WA        97701.0           101030              −3.30%   \n",
              " 10           Flint  MI        79661.0           196940             −59.55%   \n",
              " 11            Gary  IN        67652.0           178320             −62.06%   \n",
              " 12         Hammond  IN        76193.0           111698             −31.79%   \n",
              " 13         Livonia  MI        92185.0           110109             −16.28%   \n",
              " 14   Niagara Falls  NY        47599.0           102394             −53.51%   \n",
              " 15         Norwalk  CA        98078.0           105549              −7.08%   \n",
              " 16           Parma  OH        78951.0           100216             −21.22%   \n",
              " 17      Portsmouth  VA        97454.0           114773             −15.09%   \n",
              " 18         Reading  PA        94903.0           111171             −14.63%   \n",
              " 19         Roanoke  VA        99578.0           100220              −0.64%   \n",
              " 20        Scranton  PA        75805.0           143333             −47.11%   \n",
              " 21      Somerville  MA        80407.0           103908             −22.62%   \n",
              " 22      St. Joseph  MO        70634.0           102979             −31.41%   \n",
              " 23         Trenton  NJ        89620.0           128009             −29.99%   \n",
              " 24           Utica  NY        63607.0           101740             −37.48%   \n",
              " 25      Wilmington  DE        71675.0           112504             −36.29%   \n",
              " 26      Youngstown  OH        59108.0           170002             −65.23%   \n",
              " \n",
              "     Peak year Unnamed: 6  \n",
              " 0        1907        [z]  \n",
              " 1        1898       [aa]  \n",
              " 2        1950        NaN  \n",
              " 3        1950        NaN  \n",
              " 4        1990        NaN  \n",
              " 5        2020        NaN  \n",
              " 6        1960        NaN  \n",
              " 7        1960        NaN  \n",
              " 8        1920        NaN  \n",
              " 9        2020        NaN  \n",
              " 10       1960        NaN  \n",
              " 11       1960        NaN  \n",
              " 12       1960        NaN  \n",
              " 13       1970        NaN  \n",
              " 14       1960        NaN  \n",
              " 15       2010        NaN  \n",
              " 16       1970        NaN  \n",
              " 17       1960        NaN  \n",
              " 18       1930        NaN  \n",
              " 19       1980        NaN  \n",
              " 20       1930        NaN  \n",
              " 21       1930        NaN  \n",
              " 22       1900       [ab]  \n",
              " 23       1950        NaN  \n",
              " 24       1930        NaN  \n",
              " 25       1940        NaN  \n",
              " 26       1930        NaN  ,\n",
              "   vteThe 100 most populous cities of the United States  \\\n",
              " 0  New York, New York Los Angeles, California Chi...     \n",
              " 1                                                NaN     \n",
              " 2  Cities ranked by United States Census Bureau p...     \n",
              " \n",
              "   vteThe 100 most populous cities of the United States.1  \\\n",
              " 0  New York, New York Los Angeles, California Chi...       \n",
              " 1  New York, New York Los Angeles, California Chi...       \n",
              " 2  Cities ranked by United States Census Bureau p...       \n",
              " \n",
              "                                           Unnamed: 2  \\\n",
              " 0                                                NaN   \n",
              " 1  Portland, Oregon Louisville, Kentucky Memphis,...   \n",
              " 2                                                NaN   \n",
              " \n",
              "                                           Unnamed: 3  \\\n",
              " 0                                                NaN   \n",
              " 1  Arlington, Texas Aurora, Colorado New Orleans,...   \n",
              " 2                                                NaN   \n",
              " \n",
              "                                           Unnamed: 4  \n",
              " 0                                                NaN  \n",
              " 1  Chandler, Arizona North Las Vegas, Nevada Chul...  \n",
              " 2                                                NaN  ,\n",
              "     0                                                  1  \\\n",
              " 0 NaN  New York, New York Los Angeles, California Chi...   \n",
              " \n",
              "                                                    2  \\\n",
              " 0  Portland, Oregon Louisville, Kentucky Memphis,...   \n",
              " \n",
              "                                                    3  \\\n",
              " 0  Arlington, Texas Aurora, Colorado New Orleans,...   \n",
              " \n",
              "                                                    4  \n",
              " 0  Chandler, Arizona North Las Vegas, Nevada Chul...  ]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, this scrapes all the tables on the webpage, not just the one we want. As with Beautiful Soup, we can narrow the search by specifying the table attributes."
      ],
      "metadata": {
        "id": "pQwWgh_cqynb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_html(\"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\", attrs = {'class': 'wikitable sortable', \"style\": \"text-align:center\"})"
      ],
      "metadata": {
        "id": "4BKvPxa9qJ2-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "871654a5-1cbd-4b48-d0b3-a152ca324108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No tables found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-6b8fe5803685>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'wikitable sortable'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"style\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"text-align:center\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         )\n\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m     return _parse(\n\u001b[0m\u001b[1;32m   1241\u001b[0m         \u001b[0mflavor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflavor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0mio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   1001\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mretained\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# for mypy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mretained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;31m# if `io` is an io-like object, check if it's seekable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mparse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfooter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_thead_tbody_tfoot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse_tables\u001b[0;34m(self, document, match, attrs)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No tables found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No tables found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This still returns 3 tables. As we remarked above, the table that we want is the first one (see `[0]` below)."
      ],
      "metadata": {
        "id": "P6P7xCnPrBtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cities2 = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\", attrs = {'class': 'wikitable sortable', \"style\": \"text-align:center\"})[0]\n",
        "df_cities2"
      ],
      "metadata": {
        "id": "96L5qJvGp7ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wait, that seemed much easier than using Beautiful Soup, and it returned a data frame, and we even got for free some formatting like removing the commas from the population! Why didn't we just use `read_html` in the first place? It's true the `read_html` works well when scraping information from an HTML *table*. Unfortunately, you often want to scrape information from a webpage that isn't conveniently stored in an HTML table, in which case `read_html` won't work. (It only searches for `<table>`, `<th>`, `<tr>`, and `<td>` tags, but there are many other HTML tags.) Though Beautiful Soup is not as simple as `read_html`, it is more flexible and thus more widely applicable."
      ],
      "metadata": {
        "id": "TjeczIIMYeqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping information that is NOT in a `<table>` with Beautiful Soup"
      ],
      "metadata": {
        "id": "ctj79YpgX6hw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK6rJQbuuWwF"
      },
      "source": [
        "The Cal Poly course catalog http://catalog.calpoly.edu/collegesandprograms/collegeofsciencemathematics/statistics/#courseinventory contains a list of courses offered by the Statistics department. **You will scrape this website to obtain a Pandas data frame with one row for each DATA or STAT course and two columns: course name and number (e.g, DATA 301. Introduction to Data Science) and term typically offered (e.g., Term Typically Offered: F, W, SP).**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Pandas `read_html` is not help here since the courses are not stored in a `<table>.`"
      ],
      "metadata": {
        "id": "hbLLrwxs0eWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_html(\"http://catalog.calpoly.edu/collegesandprograms/collegeofsciencemathematics/statistics/#courseinventory\")"
      ],
      "metadata": {
        "id": "QIRewkca0jhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Notes/suggestions:\n",
        "\n",
        "\n",
        "- Inspect the page source as you write your code\n",
        "- The courses are not stored in a `<table>`. How are they stored?\n",
        "- You will need to write a loop to get the information for all courses, but you might want to try just scraping the info for DATA 100 first\n",
        "- What kind of tag is the course name stored in? What is the `class` of the tag?\n",
        "- What kind of tag is the quarter(s) the course is offered stored in? What is the `class` of the tag? Is this the only tag of this type with the class? How will you get the one you want?\n",
        "- You don't have to remove the number of units (e.g., 4 units) from the course name and number, but you can try it if you want\n",
        "- You will need to pull the text from the tag. If `.text` returns text with \"\\n\" at the end, try `get_text(strip = True)` instead of `text`\n",
        "- Don't forget to convert to a Pandas Data Frame; it should have 74 rows and 2 columns\n",
        "- The goal of this exercise is just to create the Data Frame. If you were going to use it then you might need to clean the data first. (You can use Beautiful Soup to do some of the cleaning for you, but that goes beyond our scope.)\n",
        "\n"
      ],
      "metadata": {
        "id": "lvSrhxS4Se7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE. ADD AS MANY CELLS AS NEEDED"
      ],
      "metadata": {
        "id": "ZbW6xon4vICB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EW2sWIGavIFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hints:\n",
        "\n",
        "- Each course is represented by a `<div>` with `class=courseblock`, so you can find all the courses with `soup.find_all(\"div\", {\"class\": \"courseblock\"})`\n",
        "- The course name is in a `<p>` tag with `class=courseblocktitle`, inside a `<strong>` tag. (Though I don't think we need to find the strong tag here.)\n",
        "- The term typically offered is in `<p>` tag with `class=noindent`. However, there are several tags with this class; term typically offered is the first one.\n",
        "- If you want to use Beautiful Soup to remove the course units (e.g., 4 units), find the `<span>` tag within the course name tag and `.extract()` this span tag"
      ],
      "metadata": {
        "id": "17e8M_OsaHJz"
      }
    }
  ]
}